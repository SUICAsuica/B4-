%%%%%%%%%%%%% TeX はソースコードを書いたらコンパイルをします（C言語の感じ） %%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% コンパイルに使うTeXの仕組みをTeXエンジンと言います（正式な言い方ではないかも） %%%%%%%%%%
%%%%%%%%%%%%% 図表番号を正しく制御するためには、2回連続でコンパイルしないといけない %%%%%%%%%%%%%%%%%%
%%%%% 参考文献を正しく制御するためには、1回コンパイル→bibtex実行→2回コンパイルしないといけない　%%%%%%%


% 以降は、コメントアウトである（コンパイル実行時には無視される）



%%%% まずは、どういう文書を作成するのかを\documentclass 文で最初に宣言する
% この宣言によって、コンパイルで使用する　texエンジンや使用できる画像ファイルが変わるので結構重要
% 色々ありすぎて保坂も体系的には理解していない

% \ で始まるものが texのコマンドである




%%%%% \documentclass[11pt,a4paper]{jsarticle}    
% 標準的な日本語原稿用だが、章(chapter)がないので、学位論文向きではない

%\documentclass[11pt,a4paper,oneside,openany]{jreport}   
% 伝統的な日本語texであるplatex (ptex2pdf)で動作するが画像(jpg, png対応）を貼ると途端に遅くなる
% bibtexは upBibtex を推奨

%%%% 結論：卒論、修士論文ではこれを使うとよい（と思う）　
%%%% ※使っていて問題があったり、もっと良いものがあれば教えてください
\documentclass[a4paper,11pt]{ltjsreport} % LuaLaTeX-ja 用クラス

% コンパイル時のtex エンジンは、　LuaLaTeX を選択すること
% bibtexは、upBibtex を使うこと
% 上記のjreport よりも高速にコンパイルが可能（LuaLaTeXの初回起動時にのみ少し時間がかかる）



%%%% ソースコードにミスがあると、コンパイルに失敗するが、たまに変な中間生成物ができてしまい
%%%% それが邪魔して、その後コンパイルができなくなる（コードを直しても失敗し続ける）ことがある。
%%%% その場合には、拡張子がtex以外の「卒業論文フォーマット」という名前のファイル（それらが中間生成物）を
%%%% すべて削除するとよい




%%%%%%% 様々な拡張機能を導入すると便利（pythonの import のような感じ）

% LuaLaTeX-ja をTeXエンジンとして利用するために必要なパッケージ（必須）
\usepackage{luatexja}

% 数式を表示するために必要なパッケージ
\usepackage{amsmath,amssymb}
\usepackage{bm}

% 図を挿入する場合に必要なパッケージ
\usepackage{graphicx}
%\usepackage[dvipdfmx]{graphicx}   % \documentclass[11pt,a4paper,oneside,openany]{jreport}  を使用する場合こちら

\usepackage{ascmac}

% 余白設定
\usepackage[top=20mm,bottom=30mm,left=20mm,right=20mm]{geometry}

% 表を作るときに複数セルを結合するために必要なパッケージ
\usepackage{multirow}  % セル結合用

% 参考文献にURLが含まれている時にURL独特の表記をするのに必要
\usepackage{url}

% 色文字を利用するために必要なパッケージ
\usepackage{color}





%%%%%%%%%%%%%% 自分専用のコマンドを作ることができる
% 新規コマンドなら \newcommand{ コマンド名 }{ 定義 }
% 既存コマンドの書き換えなら \renewcommand{ コマンド名 }{定義}

\newcommand{\Red}[1]{\textcolor{red}{#1}}     % \Red{   } で赤文字が利用できるようになる
\renewcommand{\bibname}{参考文献}   % これを書かないと最後の文献一覧が「関連図書」と表示されてしまう


%% 学会投稿をする際にTeXを利用する場合、たいがい、ここまでの記述はスタイルファイルとして与えられることが多い







\begin{document}       % ここから文書が開始
%
%

%%%%%% 表紙（★の部分を書き換えること）
\begin{titlepage}
  \centering
  ~~\vspace{1cm}
 
  {\Huge 卒　業　研　究　論　文 \par}
  {\Huge （2025年度）\par}     % ★卒業年度を西暦で入れる

  \vspace{8cm} 

   \begin{tabular}{rl}  % r=右寄せ, l=左寄せ
    {\LARGE 題　　目}　       & {\LARGE ：畳み込みニューラルネットワークによる} \\    % ★タイトル1行目を書く
                                  & {\LARGE ~~ペイント加工画像に対する撮像カメラの推定} \\ \\ \\   % ★タイトル2行目を書く
                                  % ★タイトルが1行で入るなら2行目は削除して、1行目の末尾に \\ \\ を加えること
    {\LARGE 指導教員}　 & {\LARGE ：保坂 忠明} \\　 \\ \\
    {\LARGE 学生番号}　   & {\LARGE ：12345678} \\　 \\ \\      % ★学生番号を書く
    {\LARGE 氏　　名}　       & {\LARGE ：卒論 太郎}      % ★氏名を書く
  \end{tabular}
  
  \vfil
  \begin{flushright}
    明治大学理工学部 電気電子生命学科
  \end{flushright}

\end{titlepage}





\tableofcontents   % これで目次が作られる（chapterとかsectionなどを勝手に拾ってきて自動で作ってくれる）








\chapter{序論}        % 章タイトル
この文書は当研究室のWorkの卒業論文フォーマットのTeXバージョンである。


\section{SNSへの投稿画像と事件性}     % セクションタイトル
近年、ソーシャルメディアの普及により、多くの人々がSNSへ画像や動画などのメディアを気軽に投稿できるようになった。しかし、投稿画像の中には犯罪性のあるものも増えており、最近では、特にSNS上の迷惑行為に関する投稿が問題視されている。これらの捜査にあたって、警察はSNSを積極的に活用しており、特に画像や動画の収集を行っている \cite{police}。多くの人々が所有するスマートフォンは、搭載カメラの性能も向上しており、捜査の有効な手がかりになる。元の投稿や第三者から提供された画像に写っている、人物や建造物などの情報から犯人の特定を行っている。しかし、サイバー空間上ではなりすましが可能であり、AIによるフェイク画像の生成も可能であるため、該当画像が必ずしも投稿者や情報提供者によって撮影されたとも限らない。そこで、アップロードされた画像ファイルの情報から、撮影に使われたカメラの個体が特定できれば、立証において重要な情報になり得ると考えられている。写真の画像ファイルの持つ情報として有名なのがEXIF情報である。ほぼ全てのディジタル写真に付与されており、撮影日時や撮影機種などの情報が記されている。EXIF情報を参照することにより、撮影したカメラに関する情報を得ることが可能であるが、撮影者によって簡単に改ざんすることができるため、事件の捜査において信頼性に欠ける情報である。鑑識において、付加的な情報に依存せず、撮像カメラを特定する技術に対して需要がある。


\Red{序論では、まず、社会状況（社会の中での需要）については述べるとよい。この際、適宜、文献や資料を参照するとよい。最終的に序論全体で1ページフル以上にすること。なお、\textyen subsection\{ \} でサブセクション（1.2のようなもの）、\textyen subsubsection\{ \} でサブサブセクション（1.2.1のようなもの）も作ることができる。TeXでは空行を入れると段落が変わる。}


\section{撮像カメラの推定に関する先行研究}
\Red{次に先行研究を挙げて、先行研究の問題点から繋がるようにして自分が何を研究するのか（研究目的）を述べる。本文中での文献参照の仕方としては、〇〇らの研究[3]のように著者名を挙げて参照するか（著者が一人の場合には〇〇の研究[3]とする）、文献[3]のようにするとよい。TeXの場合、文献番号を直書きするのではなく、必ず \textyen cite\{ \} を使うこと。複数文献を並べる場合には、\{ \}の間にカンマで区切って並べればよいが、カンマの前後にスペースを入れるとエラーになるか、正しく表示されないことがあるので注意。}


付加的な情報でなく、カメラ固有の情報を基に撮像カメラを推定する手法として、カメラのCCDやCMOS（電荷結合素子）と呼ばれる半導体素子に着目した方法が研究されてきた \cite{source_camera,CNN_source_camera,deep_source_camera}。カメラの画素一つ一つにフォトダイオードが対応しており、光の強さを検出して数値化している。しかし、半導体ごとに微妙に性能が異なるため、光に対する感度にばらつきが生じており、このばらつきは感度不均一性（Photo Response Non-Uniformity : PRNU）と呼ばれている。カメラによって撮影された画像に表れるPRNUの影響を強く受けた画素値に着目して推定を行うのが、この手法である。2000年代から、この特徴量に対して機械学習により個体の分類をする研究が行われてきた。M.Kharraziらの研究\cite{source_camera}では、平均ピクセル値やRGBペアの相関などの34個の項目を特徴量として、デジタルカメラによる撮影画像に対し、SVMを用いた分類手法を提案している。その結果、2種類のカメラの分類において98.73\%、5種類のカメラの分類において88.02\%の平均精度を得た。また、同様にデジタルカメラを使い、手法に深層学習を導入した手法として、Tiantianらの研究\cite{CNN_source_camera}が挙げられる。この研究では、半導体素子の性能差によって生じる、撮影画像ごと固有のノイズを手掛かりとし、畳み込みニューラルネットワークを利用した分類手法を提案している。この学習モデルには、AlexNetなどの3つの異なる学習済みの畳み込みニューラルネットワークモデルを使用している。その結果、14種類のカメラの分類において、パッチ画像を使用した場合には97.35％、画像全体を使用した場合には99.32\%の判別的中率を達成した。さらに、スマートフォンカメラによる撮影画像に対して畳み込みニューラルネットワークを利用した手法として、Aiswariyaらの研究\cite{deep_source_camera}が挙げられる。文献\cite{CNN_source_camera}とは使用した学習済みモデルが異なり、VGG16を使用している。また、スマートフォン撮影による公開データセットのRAWデータ画像を使用している。その結果、12種類のスマートフォンの識別において、87.16\%の判別的中率を達成した。しかし、これらの手法は非常に高い分類の精度を記録しているが、加工画像に対する有効性については検証されていない。

\Red{研究背景の部分で、他人の図表を引用して説明することがある。必要なら引用して構わないが、他人の文献の図表をそのまま使う場合には必ず「○○より抜粋」といれること。}


\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.6\textwidth]{研究背景画像.png}
\caption{NISAのイメージ図（金融庁HPより抜粋）：（注）この図はこの卒論にはもともとなかったものです。\Red{ここは画像挿入の例。tex codeをよく見て書式になじむこと。覚えなくても必要な部分を書き換えればよい。図の配置は [tbhp]である程度は制御できる。 top, bottom, here, page（を変える）で自分の希望順に並べる。ただし、希望通りになるとは限らない。}}    % \includegraphics の後に \captionを書くこと（図の下にキャプション）
\label{fig:test_image}  % ラベルをつけて、本文では、\ref{   } で参照すること（図が増えたり減ったりしても自動で制御される）
\end{center}
\end{figure}


\section{研究目的}
本研究では上記の研究背景を踏まえて、スマートフォンカメラによって撮影された後に加工された画像に対する撮像カメラ推定の手法を構築することを目的とする。現在ではSNSを中心に加工を施された画像が多く投稿されている。加工画像には非加工画像に比べて、元の画像に由来する情報量が減少しており、撮像カメラの推定はより難しくなることが予想される。しかし、昨今では警察はSNS上の画像も捜査に用いており、提案手法により加工画像に対する撮像カメラの推定が可能となれば、捜査において役立つことが期待できる。具体的な設定としては、撮影機材としては広く用いられているスマートフォンカメラに限定し、加工の種類としてはペイントによる落書きを対象とする。 
\Red{\\ 研究目的は、前節で述べた先行研究の欠点や未解決な点を解決するという書き方が基本。ぱっと見て分かるように、「〇〇〇を目的とする」と最初の文で言い切るのが理想。たまに、「・・・を目的とする。・・・を目指す。・・・を目的とする。」のように何度も目的とか目指すを繰り返す人がいるがどれが本当の目的なのか分かりにくくなるので「目的とする」は一度だけにして、残りは補足説明的に添えるのがよい。}

\section{本論文の構成}
\Red{序論の最後の節は、「本論文の構成」を書く。後続の各章で何を述べるのかを章ごとに数行程度（長くなる分には構わない）で述べる。TeXでは章や節の番号も参照できる。下の「2章」のところのTeX codeを見てみるとよい。}

\ref{chap:method}章では研究の手法について述べる。実験に使用した画像データや、提案する推定アルゴリズム、そして利用した畳み込みニューラルネットワークのモデルなどについて述べる。

3章では評価実験の結果を述べる。提案手法によって、加工画像に対する推定精度を示す。また、畳み込みニューラルネットワークモデルや画像加工の割合によって、撮像カメラの推定精度がどのように変化したか述べる。

4章では考察について述べる。

5章ではまとめの今後の課題について述べる。本研究において提案した手法をまとめるのとともに、今後の課題について述べる。




\chapter{分析手法}
\label{chap:method}    % \chapterとか\sectionの後で \labelをつけると、章や節の番号を\refで参照できる

\Red{先行研究の後には、分析手法（章の名前はふさわしいものに変えてよい）を書く。どんなデータを取得して、どのような方法で分析したかを分かりやすく述べる。結果についてはまだ述べない。人文社会系でよくある要因分析のような研究なら、取得データをこの章で示せばいいが、脳波研究のようなものは、測定したデータも結果の一部とみなせるので、次の結果の章で示した方がよいことが多い。何を述べるかをよく考えること。}

\section{研究の流れ}

本研究の流れは、以下の通りである。
\begin{enumerate}
\item	スマートフォンカメラを使用して画像データを取得する。
\item	上記で取得した画像のうち、テストデータの画像にペイント加工を加える。具体的には、ランダムな位置・色の正方形を、指定した割合に基づいて配置する。
\item	学習データを利用して、公開されている学習済みの畳み込みニューラルネットワーク（Convolutional Neural Network：CNN）モデルに対して転移学習を行う。
\item	加工されたテストデータを用いて評価を行う。加工割合やCNNモデルの条件を変えながら、撮像カメラの推定精度の変化を確認する。
\end{enumerate}

\Red{上は箇条書きの例であり、enumerate環境で作った。他にも黒ポチにするとか、先頭に見出しワードをつけるとか色々ある。分からなければ自分で調べるか、ChatGPTにこんな箇条書きにしたいからtexコードをくれ、とお願いすれば生成してくれる。}




\section{使用したデータの概要}
本研究ではiPhone Xs 2台、AQUOS sense6 1台、Galaxy A21 1台の計4台のスマートフォンを使用し、背面カメラでの撮影によって合計4400枚の画像データを取得した。その内訳は、スマートフォン1台につき学習データ1000枚とテストデータ100枚の計1100枚である。学習データについては200個の被写体から成り、1つの被写体あたり5枚の写真を撮影している。テストデータについては、全て異なる被写体を撮影している。また、学習済みCNNモデルに対する転移学習を行うために、全ての画像について、左上からの切り取りにより縦横250ピクセルの大きさに統一している。図\ref{fig:test_image}はテストデータの例である。


\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.3\textwidth]{test_image1.png} ~~~
\includegraphics[width= 0.3\textwidth]{test_image2.png} 
\caption{テストデータの例：\Red{ここは2枚を並べて画像挿入する例。tex codeをよく見て書式になじむこと。覚えなくても必要な部分を書き換えればよい。図の配置は [tbhp]である程度は制御できる。 top, bottom, here, page（を変える）で自分の希望順に並べる。ただし、希望通りになるとは限らない。}}    % \includegraphics の後に \captionを書くこと（図の下にキャプション）
\label{fig:test_image}  % ラベルをつけて、本文では、\ref{   } で参照すること（図が増えたり減ったりしても自動で制御される）
\end{center}
\end{figure}



\section{テストデータに対する加工}
\Red{章のタイトルは短くて良いが、各節（セクション）のタイトルは上のようになるべく具体的にした方がよい（結果的に少し長くなってよい）}

テストデータへのペイント加工として、pythonプログラムによって正方形を配置することで塗りつぶしを行った。具体的には、指定した塗りつぶし割合に基づいて、25×25サイズの正方形の個数を自動計算し、画像中のランダムな位置にその個数分の正方形を配置する。さらに、それぞれの正方形の色をランダムに変更している。この加工画像の例を図\ref{fig:paint_image}で示す。塗りつぶし割合は、0～10\%の1\%刻み、15\%、20\%の計13段階で指定した。10\%以降は5\%刻みになっているのは、これ以降の判別精度の変化があまり見られなかったためである。



\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.3\textwidth]{ペイント画像1.jpg} ~~~
\includegraphics[width= 0.3\textwidth]{ペイント画像2.jpg} 
\caption{ペイント加工を施したテストデータの例}
\label{fig:paint_image}
\end{center}
\end{figure}




\section{深層学習モデル}

本研究では、学習済みの公開されているCNNモデルを使用した転移学習を行う。CNNとは、主に画像認識やパターン検出に使用される深層学習モデルである。画像内のパターンやエッジを抽出する畳み込み層と、情報を簡略化するプーリング層から主に構成されており、画像を小さな領域に分けて特徴を抽出している。

また、転移学習とは深層学習の一手法で、モデルが学習した知識を別のタスクでの学習に適用する方法である。通常、深層学習モデルはタスクに合わせて大量なデータを必要とするが、転移学習を使用して学習済みのモデルや特徴を適用することで、学習データの不足や計算リソースの制約を克服できる。本研究で使用する画像データは合計で4400枚であり、一般的な基準と比較して少ないため、この手法を採用した。

本研究では転移学習に使用する学習済み公開CNNモデルとして、VGG16とResNetを採用した。VGG16は先行研究\cite{deep_source_camera}で使用されており、ResNetは画像認識において高い性能を出すことができる。また、評価実験での計算リソースが限られることから、この2つのモデルを採用した。

VGG16は13個の畳み込み層と5個のプーリング層、そして3個の全結合層から構成されるCNNモデルである。畳み込み層では3×3の比較的小さなフィルターを使用しており、パラメータ数は増加するものの、画像中の局所的な特徴が畳み込み層を通じて階層的に抽出され、豊富な特徴表現を得ることができる。畳み込み層とプーリング層、そして全結合層からのシンプルな構造にも関わらず、汎化性能が高く、小規模のデータセットや計算資源に制約のある状態でも効果的な学習と予測を行うことができる。

ResNetは残差ブロックと呼ばれる構造を導入したCNNモデルである。一般的なCNNモデルでは、層を深くすることで勾配消失と呼ばれる問題が発生する。各パラメータに対する損失関数の勾配が、モデルの出力から入力に逆伝播するが、勾配が小さくなると勾配降下法によるパラメータ更新が難しくなる。特に最初の層では勾配が非常に小さくなるため、パラメータはほとんど更新されない。これにより初期の層が適切に学習されず、モデル全体の性能が低下してしまうのが勾配消失である。これに対しResNetでは残差ブロックを導入することにより、逆伝播の過程で直結した残差が初期の層へ逆伝播され、その勾配が初期の層のパラメータ更新に寄与する。そして、初期の層でも有益な勾配が残り、勾配消失の問題が軽減される。これによってResNetは、特にモデルが非常に深くなる場合でも安定して優れた学習を行うことができる。

さらに学習アルゴリズムについては、学習率を0.0001として最適化アルゴリズムAdamを使用し、Early Stoppingによって、5エポック連続で検証データに対する的中率が上がらなくなったら重み係数の学習を停止した。なお、訓練時のパラメータとしてバッチサイズは64、エポック数は100、検証データは学習データの10\%を指定した。

本研究での学習環境には、Google Colaboratoryを使用した。




\section{評価方法}
学習及びテストデータへの加工をやり直しながら、塗りつぶし割合ごとに5回の推定実験を行い、その判別的中率を求める。そうして得られた5つの判別的中率の平均値を、その条件における判別精度とする。この実験を、iPhone XsとAQUOS sense6による異なる2つのモデル間での推定、2台のiPhone Xsによる同じ2つのモデル間での推定、iPhone XsとAQUOS sense6とGalaxy A21による異なる3つのモデル間での推定で行う。




\section{数式の利用}
\Red{この卒業論文には数式が存在しないため、ここで数式の使い方を示す。}


\Red{文章中に数式を示すためには、$y = x^2 + \sin(x) + \sum_{i=0}^\infty \log_2 i $ のように\$ ..... \$ で囲めばよい。tex codeをよく見ること。}

\Red{別行立ての式は
\begin{eqnarray}
y_1 & = & x^3 + x^2 +4, \label{eq1} \\
y_2 & = & \int^\infty_{-\infty} \frac{1}{x^2+4} + \bm{\alpha} \cdot \bm{\beta}  \label{eq2}
% & で挟まれた部分が縦に揃う（普通は = の位置で揃える）
% \\は改行、改行記号の前に\labelを入れる（どこでも参照しない数式なら無理に\labelを作らなくてもよい
\end{eqnarray}
のように eqnarray 環境を使えばよい。自動で式番号が挿入されるが、式番号を入れたくない場合には、eqnarray* とすればよい。式番号は、図表と同様に ref\{  \} で参照することができ、例えば「式(\ref{eq1})を式(\ref{eq2})に代入すると、$y=\pi$ であることが分かる」のように使うことができる。tex codeをよく見ること。自分が示したい数式がtex codeでどのように表現できるかは都度調べればよい。なお、WordやPowerPointの数式ビルダもtexの数式表現を受け付けるので、texの数式表現を覚えると、WordやPowerPointでの入力も早くなる。}





\chapter{分析結果}
\Red{手法の後に、得られた結果を述べる（適宜、章タイトルは変えてよい）。研究によっては、結果と考察を併せて述べた方が書きやすいので、そういう場合は一緒にしてもよい。考察だけ独立させたければ次の章にする。たいがい、卒研では何パターンかの分析をするはずなので、パターンごとにセクションを分けると書きやすい。}


\section{異なる２つのカメラモデル間での推定結果}
図\ref{fig:result1}に、iPhone XsとAQUOS sense6の2台を使用した実験における推定精度とその変化のグラフを示す。塗りつぶし割合が大きくなるにつれて判別的中率が低下している。0～20\%の中でも、VGG16では3\%、ResNetでは4\%まで加工割合を増加させると、判別的中率が大きく低下した。一方で、それ以降の割合においては、精度が低下しにくくなっている。さらに、10\%以上の加工画像については、精度はほとんど50\%になっており、推定能力がほぼ無いことが分かる。

表\ref{table:result1-1}と\ref{table:result1-2}は、塗りつぶし割合が0\%と10\%のときの判別結果に関する混同行列である。0\%のときにはほとんど正しい判別が行われている。一方で10\%のときには、AQUOSの9割をiPhoneと判別してしまっており、塗りつぶしが多くなることで、判別がiPhone寄りになったと考えられる。



\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.75\textwidth]{結果1.png} 
\caption{塗りつぶし割合と判別的中率}
\label{fig:result1}
\end{center}
\end{figure}



\begin{table}[htbp]
\centering
\caption{塗りつぶし割合0\%のときの混同行列: \Red{これは標準的なTeXの表の作り方になっている。tex codeをよく見てなじむこと。覚えなくてもよくて、必要なときに必要部分を書き換えるか、ChatGPTにお願いすればよい。}}  %表の \captionは　\begin{tabular}の上に書く
\begin{tabular}{|c|c|c|c|}     % 何列の表なのかを指定　　　| は区切り線を入れることを表す　　cは中央揃え(l,rも指定可）
\hline    % horizontal line 横線のこと（ここは、表の上辺）
 &  & 推定  & \\ \hline      % 列の区切りが　& 、  \\は改行
 &  & iPhone & AQUOS \\ \hline
正解 & iPhone & 95\% & 5\% \\ \hline
 & AQUOS & 1\% & 99\% \\ \hline
\end{tabular}
\label{table:result1-1}    %ラベルをつけて、本文では \ref{   } で参照すること
\end{table}


\begin{table}[htbp]
\centering
\caption{塗りつぶし割合10\%のときの混同行列: \Red{multicolumnパッケージを導入して左上部分の4セルを結合して見栄えをよくした表(multicolumnの使い方が分からなくてもChatGPTに生成してもらえばよい）}}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{}} & \multicolumn{2}{c|}{推定} \\ \cline{3-4}
\multicolumn{2}{|c|}{} & iPhone & AQUOS \\ \hline
\multirow{2}{*}{正解} & iPhone & 100\% & 0\% \\ \cline{2-4}
 & AQUOS & 90\% & 10\% \\ \hline
\end{tabular}
\label{table:result1-2}
\end{table}


\section{同じ２つのモデル間での推定結果}

図\ref{fig:result2}に、iPhone Xs 2台を使用した実験における推定精度とその変化のグラフを示す。この実験でも、塗りつぶし割合が大きくなるにつれて判別的中率が低下している。異なる2つのモデル間での推定と比較すると、塗りつぶし割合が低いときの判別的中率は低く、判別的中率は減少しにくくなっている。また、塗りつぶし割合が10\%以降では判別的中率が50\%より大きい点が異なっている。

表\ref{table:result2-1}と表\ref{table:result2-2}は、塗りつぶし割合が0\%と10\%のときの判別結果に関する混同行列である。全体的な精度は低下しているものの、0\%のときには大方正しい判別ができている。一方で10\%のときには、片方のiPhoneの9割をもう一方のiPhoneと判別している。異なる2つのモデル間での推定と同様に、塗りつぶしが大きくなることで、判別が片方寄りになりやすくなっている。


\begin{figure}[htb]      % tbhpは全部書かなくてもよい
\begin{center}
\includegraphics[width= 0.75\textwidth]{結果2.png} 
\caption{塗りつぶし割合と判別的中率}
\label{fig:result2}
\end{center}
\end{figure}



\begin{table}[pbt]
\centering
\caption{塗りつぶし割合0\%のときの混同行列: \Red{これは表を画像として貼り付けた例。tex codeをよく見てみること。}}
\label{table:result2-1}
\includegraphics[width=0.5\textwidth]{result2_table.png}
\end{table}



\begin{table}[pbt]
\centering
\caption{塗りつぶし割合10\%のときの混同行列}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{}} & \multicolumn{2}{c|}{推定} \\ \cline{3-4}
\multicolumn{2}{|c|}{} & iPhone & AQUOS \\ \hline
\multirow{2}{*}{正解} & iPhone & 2\% & 98\% \\ \cline{2-4}
 & AQUOS & 0\% & 100\% \\ \hline
\end{tabular}
\label{table:result2-2}
\end{table}





\section{異なる３つのモデル間での推定結果}
図\ref{fig:result3}に、iPhone XsとAQUOS sense6とGalaxy A21の3台を使用した実験における推定精度とその変化のグラフを示す。2台の推定の場合と比較して、低い塗りつぶし割合では比較的高い判別精度であったが、割合が高くなると判別精度は低めとなった。

表\ref{table:result3-1}と表\ref{table:result3-2}は、塗りつぶし割合が0\%と10\%のときの判別結果に関する混同行列である。推定するモデルが3つの場合でも、塗りつぶしが大きくなることで、判別が1つのモデルに偏るようになっている。この推定ではGalaxyに偏ったが、AQUOSのほとんどがGalaxyに誤って判別されているのに対し、iPhoneは半分が誤ってGalaxyに判別されている。



\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.75\textwidth]{結果3.png} 
\caption{塗りつぶし割合と判別的中率}
\label{fig:result3}
\end{center}
\end{figure}



\begin{table}[tb]
\centering
\caption{塗りつぶし割合0\%のときの混同行列}
\label{table:result3-1}
\includegraphics[width=0.5\textwidth]{result3_table.png}
\end{table}



\begin{table}[tbph]
\centering
\caption{塗りつぶし割合10\%のときの混同行列}
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{}} & \multicolumn{3}{c|}{推定} \\ \cline{3-5}
\multicolumn{2}{|c|}{} & iPhone & AQUOS & Galaxy \\ \hline
\multirow{3}{*}{正解} & iPhone & 53\% & 0\% & 47\% \\ \cline{2-5}
 & AQUOS & 6\% & 0\% & 94\% \\ \cline{2-5}
 & Galaxy & 2\% & 0\% & 98\% \\ \hline
\end{tabular}
\label{table:result3-2}
\end{table}


\Red{結果を踏まえて、さらなる付加的な実験をした場合には、次に独立した章を作って述べても構わない。ただし、あまり文量がないならば、「結果」か「考察」の章に組み込んでしまってよい。}



\chapter{考察}
本章では、これまでの評価結果を基に考察を述べる。

\section{評価実験に関する考察}
図\ref{fig:result1}、\ref{fig:result2}、\ref{fig:result3}から、塗りつぶし割合が増加するに従って判別精度が低下した。PRNUの影響を強く受けた画素が塗りつぶされることで、判別の手がかりを失ってしまうためである。塗りつぶし割合が大きくなると、手がかりが少なくなり判別が難しくなってしまう。また表\ref{table:discussion}は、異なる2つのモデル間での推定実験において得られた5回分の判別的中率とその平均値である。この結果のように、同じ条件下の実験であっても10\%以上の精度差が生じることもあった。同じ塗りつぶし割合でも、ペイントのランダムな配置場所によって、精度の差が生じるようであった。


\begin{table}[htbp]
\centering
\caption{異なる2つのモデル間での5回の推定結果と平均値（塗りつぶし割合4\%、ResNet使用）}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
1回目 & 2回目 & 3回目 & 4回目 & 5回目 & 平均値 \\ \hline
60.0 & 68.0 & 72.0 & 60.0 & 63.5 & 64.7  \\ \hline
\end{tabular}
\label{table:discussion}
\end{table}


また、無加工の場合の推定精度が先行研究と比較して低下しているが、これは画像の性質によるものである。本研究ではスマートフォンによる撮影画像をそのまま実験データとして使用しているのに対し、先行研究ではRAWデータの公開データセットを用いている。RAWデータは、スマートフォンによる補正を受ける前の画像データであり、PRNUの影響が画素値に表れやすくなっているために、先行研究の方が高い精度になっていると考えられる。しかしRAWデータでなくても、異なる2種類のモデルにおける判別では94\%、異なる3種類モデルにおける判別では90\%の精度を得ることができると分かった。


\section{手法改善に関する評価実験と結果}
表\ref{table:result1-1}-\ref{table:result3-2}で示された混同行列から分かるように、塗りつぶし割合が高い場合、推定したクラスが１つに偏ることが多々あった。この偏りの原因として、単色の正方形を配置する「べた塗り」加工が可能性としてあると考えた。さらには、この偏りを解消することで、推定精度の向上も期待できると考え、原画像に近い加工を施して比較することにした。具体的には、ペイント加工部分に、原画像の任意の画素値を抜き出して貼り付ける加工を行った。この加工画像の例を図\ref{fig:discussion}に示す。




\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.3\textwidth]{考察画像1.png} ~~~
\includegraphics[width= 0.3\textwidth]{考察画像2.png} 
\caption{元の画像に近いペイント加工をしたテストデータの例}
\label{fig:discussion}
\end{center}
\end{figure}




この方法による加工画像とべた塗りの加工画像をテストデータとする推定結果を比較したものが図\ref{fig:result4}である。この実験では、iPhone XsとAQUOS sense6の2台を使用し、CNNモデルにはResNetを使用している。べた塗りでない加工にすることで、推定精度が向上した。特に推定の偏りが多かった、塗りつぶし割合が10\%以降の推定では、15\%近くも判別精度が向上している。高い塗りつぶし割合ほど、偏りが多くなるため、この方法が有効であると分かった。また、塗りつぶし割合の増加に伴う推定精度の低下も、緩やかなものとなった。


表\ref{table:result4}7は、塗りつぶし割合が10\%のときの判別結果に関する混同行列である。依然として判別がiPhoneに偏っているが、表2と比較すると13\%のデータについてAQUOSの正しい判別が行われ、偏りが軽減された。以上のことから、べた塗りでなく原画像由来の塗りつぶしを行うことで、判別の偏りが軽減され、全体的な判別精度が向上することが分かった。べた塗り加工では画素値の手がかりを失ってしまうために、モデル側は判別が難しく偏った結果を出しやすくなる。一方でこの加工方法では、手がかりが別の画素へ移動しただけであり、モデル側は手がかりの場所が異なってもPRNUの影響を受けた画素値を認識する場合がある。その結果、偏りの改善と判別精度の向上に繋がったのだと考える。



\begin{figure}[tbhp]
\begin{center}
\includegraphics[width= 0.75\textwidth]{結果4.png} 
\caption{塗りつぶし割合と判別的中率}
\label{fig:result4}
\end{center}
\end{figure}



\begin{table}[tb]
\centering
\caption{塗りつぶし割合10\%のときの混同行列}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{2}{|c|}{\multirow{2}{*}{}} & \multicolumn{2}{c|}{推定} \\ \cline{3-4}
\multicolumn{2}{|c|}{} & iPhone & AQUOS \\ \hline
\multirow{2}{*}{正解} & iPhone & 100\% & 0\% \\ \cline{2-4}
 & AQUOS & 77\% & 23\% \\ \hline
\end{tabular}
\label{table:result4}
\end{table}

~~\\   % これがないと、最後の表が1個だけでページ中央に表示されて格好悪い（試しにこれを外してコンパイルしてみるとよい）
% たまにこういう微妙な位置調整をしないといけないこともある（なんとなくtexを使う意義から外れるので本当は嫌だがしょうがない）
% ~ は半角空白　\\ は改行を表す（見えない文字を挿入していることになる）







\chapter{結論}
\Red{「結論」の章は、要は「まとめと今後の課題」と考えてよい。（研究背景⇒）目的 ⇒ 手法 ⇒ 結果を改めて書く（結果だけ書くのはダメ；研究背景は書かなくてもよい）、その後に今後の課題を述べる。全部で1ページフル～2ページくらいは書いて欲しい。}

\Red{《書き方のポイント》 \\
この章は、総復習＋今後の課題です。
総復習は、これまでのすべての章について、各１段落～２段落くらいでまとめてください。ここまでに書いてきた章を短くまとめるだけなので簡単なはずです。最後に今後の課題を１段落～２段落くらいで書いてください。
}



SNSの普及に伴い、誰もが簡単に画像などのメディアを投稿しやすくなったことで、事件性のある投稿も増えるようになっている。警察は捜査のためにSNS上の画像や動画の収集を行っており、事件関係者の特定に利用している。しかし、EXIF情報などの付加的な情報は改ざんが可能となっているため、カメラ固有の情報に基づく撮像カメラの特定技術が必要とされている。カメラ固有の情報に基づいた撮像カメラの推定手法として、半導体素子の性能差を利用する手法がある。半導体素子は光への感度にばらつきがあり、その影響は画素値に表れる。このばらつきを特徴量とした機械学習によりカメラを推定する研究が多く行われてきた。しかしこの手法に関する研究において、加工画像に対する推定は扱われていないが、実際にはSNS上で多くの加工画像が投稿されている。また、これらの多くの研究では、特殊な方法によって得られるRAWデータ画像を使用しており、ソフトウェアによる補正を受ける前の、光への感度のばらつきによる影響が画素値に表れやすくなっている画像を扱っている。そのことから本研究では、鑑識における実用性の観点から、RAWデータでなくスマートフォンによる撮影された画像データを用いて、畳み込みニューラルネットワークを使用した加工画像に対する撮像カメラの推定に取り組んだ。

本研究では、スマートフォンカメラによって撮影・ペイント加工を施した画像に対する撮像カメラの推定を行うことを目的とし、畳み込みニューラルネットワークを用いて判別を行った。実験データには、2台のiPhone Xs、1台のAQUOS sense6、1台のGalaxy A21のカメラを使用して撮影した、4000枚の学習データと400枚のテストデータを使用した。転移学習を行うため、全ての画像を縦横250ピクセルに統一している。テストデータについては、pythonを使用して、任意の場所に25×25ピクセルのランダムな色の正方形を、指定した塗りつぶし割合の個数分配置することでペイント加工を施した。畳み込みニューラルネットワークには、公開CNNモデルであるVGG16とResNetを使用した転移学習を行った。実験には、iPhone XsとAQUOS sense6の異なる2つのモデル、iPhone Xs同士の同じ2つのモデル、iPhone XsとAQUOS sense6とGalaxy A21の異なる３つのモデル、以上の３通りの推定を行った。使用するCNNモデルや塗りつぶし割合の条件を変えながら、条件ごとに5回ずつ判別的中率を得て、その平均値を判別精度とした。

評価実験の結果、どの判別においても、塗りつぶし割合が画像全体の10\%までの塗りつぶしであっても、判別精度は大きく低下した。一方で10\%以降では、判別精度は比較的減少しにくくなった。また、特に10\%以上におけるカメラの推定結果は1台に偏りが生じやすくなってしまい、この要因が精度の低下を招いていることが分かった。

そこで本研究では、塗りつぶし方法を単色による「べた塗り」でなく、原画像に由来する画素値を用いる方法に変えて評価実験を行ったところ、撮像カメラの偏りが軽減され、判別精度も向上した。特に推定結果の偏りが多かった、塗りつぶし割合10\%以降の画像に対する推定については、判別精度が15\%近く向上した。

本研究では加工画像としてペイント加工に焦点を当てた。しかし、実際にSNSではスタンプや落書きなどによる塗りつぶしだけでなく、拡大・縮小やモザイク加工が施された画像も多く投稿されている。それらの加工画像に対する撮像カメラの推定精度を調査することで、鑑識における実用性のある結果が得られると思われる。また、本研究では使用した実験データ数が少ないために転移学習を行い、CNNモデルにはVGG16とResNetの2種類を用いた。撮像カメラの推定のためのCNNモデルを設計したり、学習済み公開CNNモデルに改善を施したりすることで、加工画像にも耐性のある推定モデルが期待できると考える。





\chapter*{謝辞}       % * をつけると章番号が表示されない
\addcontentsline{toc}{chapter}{謝辞}   % *をつけた場合、標準では目次に表示されない。これを追加すると表示される。
本研究では、様々なご指導頂きました保坂先生、またアドバイスをくださった研究室の皆に深く感謝しております。

\Red{多くの場合に指導教員に対する謝辞を書くが、書きたくなければ書かなくてもよい。その他、研究室メンバーの助力が大きかった場合（共同研究の場合など）、外部機関から研究費の援助を受けた場合、家族に対して謝辞を述べたい場合には書くとよい。}


\bibliographystyle{junsrt}    % 参考文献の表示スタイル（これは、日本語対応で、本文引用順に表示するスタイル）
\bibliography{mybibfile}     % mybibfile.bib ファイルを読み込む







\appendix
\chapter{＊＊＊＊＊のデータ一覧}
\Red{付録には本文に載せきれない結果やデータなどを載せる。珍しいデバイス（脳波計やkinectなど）の使用方法や授業では教わらないような分析の実装方法は後輩にとって有用となるので基本的に載せてよい。一方で、掲載してもまず読まれないような細かい全データなどは載せなくてよい。また、画像処理やシステム開発のプログラムのソースコードも基本的に不要。付録に載せていいかどうかは事前に相談すること。本文の対応箇所で必ず「〇〇については付録を参照して頂きたい。」と入れること。}

\Red{TeXの場合、\textyen appendix　と宣言すると、それ以降は付録として扱われる。}



%
%
\end{document}
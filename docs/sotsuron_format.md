# 卒業論文フォーマット

卒 業 研 究 論 文
（20＊＊（西暦数字を入れる）年度）

題

目

畳み込みニューラルネットワークによる

ペイント加工画像に対する撮像カメラの推定
（2 行に分けるときは切れ目の良い所で）

指 導 教 員

保坂忠明

学生番号

********

氏

卒論太郎

名

上記各項目の先頭文字の位置が一直線に揃うように（飛び出たり、へこんだりしないよう
に）。また、各項目の下線の長さもまちまちにならないように注意。
表紙にはページ番号不要


---

明治大学理工学部 電気電子生命学科

内容

目次は自動生成すること！（検索すればやり方分かる）

1.序論 .................................................................................................................................................... 2
1.1 SNS への投稿画像と事件性 ......................................................................................................... 2
1.2 撮像カメラの推定に関する先行研究............................................................................................ 2
1.3 研究目的...................................................................................................................................... 3
1.4 本論文の構成............................................................................................................................... 3
2.分析手法 ............................................................................................................................................. 4
2.1 研究の流れ .................................................................................................................................. 4
2.2 使用したデータの概要................................................................................................................. 4
2.3 テストデータに対する加工 .......................................................................................................... 4
2.4 深層学習モデル ........................................................................................................................... 5
2.5 評価方法...................................................................................................................................... 6
3.分析結果 ............................................................................................................................................. 7
3.1 異なる２つのモデル間での推定結果............................................................................................ 7
3.2 同じ２つのモデル間での推定結果 ............................................................................................... 8
3.3 異なる３つのモデル間での推定結果............................................................................................ 9
4.考察 .................................................................................................................................................. 10
4-1 評価実験に関する考察 .............................................................................................................. 10
4-2 手法改善に関する評価実験と結果 ............................................................................................. 10
5.結論 .................................................................................................................................................. 12
謝辞..................................................................................................................................................... 14
参考文献.............................................................................................................................................. 15

目次の作り方の参考ページ
https://next.rikunabi.com/journal/20170801_s03/

1


---

（リンク切れの場合には Google などで検索すること；いくらでもネット上に情報はある）
このページを 1 ページ目として、ページ番号をページ中央下部に表示すること

1. 序論
↑のように章タイトルは本文より少し大きく 20 ポイントでよい
1.1 SNS への投稿画像と事件性
余白（上 2 ㎝、下 3 ㎝、左 2 ㎝、右 2 ㎝）は、このファイルのフォーマットのままにすること（勝手
に変えてはいけない）。本文は 10.5 ポイントの明朝体で書く。右端がガタガタに揃わなくなることがあ
るため，両端揃えにするとよい。意味のまとまりごとに適度に段落を作ること。
序論では、まず、社会状況（社会の中での需要）については述べるとよい。この際、適宜、文献や資
料を参照するとよい。最終的に序論全体で 1 ページフル以上にすること。
近年、ソーシャルメディアの普及により、多くの人々が SNS へ画像や動画などのメディアを気軽に
投稿できるようになった。しかし、投稿画像の中には犯罪性のあるものも増えており、最近では、特に
SNS 上の迷惑行為に関する投稿が問題視されている。これらの捜査にあたって、警察は SNS を積極的
に活用しており、特に画像や動画の収集を行っている[1]。多くの人々が所有するスマートフォンは、搭
載カメラの性能も向上しており、捜査の有効な手がかりになる。元の投稿や第三者から提供された画像
に写っている、人物や建造物などの情報から犯人の特定を行っている。しかし、サイバー空間上ではな
りすましが可能であり、AI によるフェイク画像の生成も可能であるため、該当画像が必ずしも投稿者や
情報提供者によって撮影されたとも限らない。そこで、アップロードされた画像ファイルの情報から、
撮影に使われたカメラの個体が特定できれば、立証において重要な情報になり得ると考えられている。
写真の画像ファイルの持つ情報として有名なのが EXIF 情報である。ほぼ全てのディジタル写真に付与
されており、撮影日時や撮影機種などの情報が記されている。EXIF 情報を参照することにより、撮影
したカメラに関する情報を得ることが可能であるが、撮影者によって簡単に改ざんすることができるた
め、事件の捜査において信頼性に欠ける情報である。鑑識において、付加的な情報に依存せず、撮像カ
メラを特定する技術に対して需要がある。参考文献は[1], [2]のようにして示すこと。
研究背景の部分で、他人の図表を引用して説明することがある。必要なら引用して構わないが、他
人の文献の図表をそのまま使う場合には必ず「○○より抜粋」と必ずいれること。

2


---

図＊

NISA のイメージ図（金融庁 HP より抜粋）

（注）この図はこの卒論にはもともとなかったものです
1.2 撮像カメラの推定に関する先行研究
次に先行研究を挙げて、先行研究の問題点から繋がるようにして自分が何を研究するのか（研究目的）
を述べる。本文中での文献参照の仕方としては、〇〇らの研究[3]のように著者名を挙げて参照するか（著
者が一人の場合には〇〇の研究[3]とする）、文献[3]のようにするとよい。
付加的な情報でなく、カメラ固有の情報を基に撮像カメラを推定する手法として、カメラの CCD や
CMOS（電荷結合素子）と呼ばれる半導体素子に着目した方法が研究されてきた[2][3][4]。カメラの画
素一つ一つにフォトダイオードが対応しており、光の強さを検出して数値化している。しかし、半導体
ごとに微妙に性能が異なるため、光に対する感度にばらつきが生じており、このばらつきは感度不均一
性（Photo Response Non-Uniformity : PRNU）と呼ばれている。カメラによって撮影された画像に表
れる PRNU の影響を強く受けた画素値に着目して推定を行うのが、この手法である。2000 年代から、
この特徴量に対して機械学習により個体の分類をする研究が行われてきた。M.Kharrazi らの研究[2]で
は、平均ピクセル値や RGB ペアの相関などの 34 個の項目を特徴量として、デジタルカメラによる撮影
画像に対し、SVM を用いた分類手法を提案している。その結果、2 種類のカメラの分類において 98.73%、
5 種類のカメラの分類において 88.02%の平均精度を得た。また、同様にデジタルカメラを使い、手法に
深層学習を導入した手法として、Tiantian らの研究[3]が挙げられる。この研究では、半導体素子の性能
差によって生じる、撮影画像ごと固有のノイズを手掛かりとし、畳み込みニューラルネットワークを利
用した分類手法を提案している。この学習モデルには、AlexNet などの 3 つの異なる学習済みの畳み込
みニューラルネットワークモデルを使用している。その結果、14 種類のカメラの分類において、パッチ
画像を使用した場合には 97.35％、画像全体を使用した場合には 99.32％の判別的中率を達成した。さ
らに、スマートフォンカメラによる撮影画像に対して畳み込みニューラルネットワークを利用した手法
として、Aiswariya らの研究[4]が挙げられる。文献[3]とは使用した学習済みモデルが異なり、VGG16
を使用している。また、スマートフォン撮影による公開データセットの RAW データ画像を使用してい
る。その結果、12 種類のスマートフォンの識別において、87.16%の判別的中率を達成した。しかし、
これらの手法は非常に高い分類の精度を記録しているが、加工画像に対する有効性については検証され
ていない。セクションの切れ目は↓のように改行を入れてよい。

3


---

1.3 研究目的

前節で述べた先行研究の欠点や未解決な点を解決するという書き方が基本

本研究では上記の研究背景を踏まえて、スマートフォンカメラによって撮影された後に加工された画
像に対する撮像カメラ推定の手法を構築することを目的とする。現在では SNS を中心に加工を施され
た画像が多く投稿されている。加工画像には非加工画像に比べて、元の画像に由来する情報量が減少し
ており、撮像カメラの推定はより難しくなることが予想される。しかし、昨今では警察は SNS 上の画
像も捜査に用いており、提案手法により加工画像に対する撮像カメラの推定が可能となれば、捜査にお
いて役立つことが期待できる。具体的な設定としては、撮影機材としては広く用いられているスマート
フォンカメラに限定し、加工の種類としてはペイントによる落書きを対象とする。
ぱっと見て分かるように、
「〇〇〇を目的とする」と最初の文で言い切るのが理想。たまに、
「・・・を
目的とする。
・・・を目指す。
・・・を目的とする。」のように何度も目的とか目指すを繰り返す人がいる
がどれが本当の目的なのか分かりにくくなるので「目的とする」は一度だけにして、残りは補足説明的
に添えるのがよい。
1.4 本論文の構成
序論の最後の節は、
「本論文の構成」を書く。後続の各章で何を述べるのかを章ごとに数行程度（長く
なる分には構わない）で述べる。
2 章では研究の手法について述べる。実験に使用した画像データや、提案する推定アルゴリズム、そ
して利用した畳み込みニューラルネットワークのモデルなどについて述べる。
3 章では評価実験の結果を述べる。提案手法によって、加工画像に対する推定精度を示す。また、畳
み込みニューラルネットワークモデルや画像加工の割合によって、撮像カメラの推定精度がどのように
変化したか述べる。
4 章では考察について述べる。
5 章ではまとめの今後の課題について述べる。本研究において提案した手法をまとめるのとともに、
今後の課題について述べる。
章の切れ目に関しては空行部分を残して改ページしてよいが、それ以外のところでは改ページはしない。
各ページの下まできっちり文章を書くこと。

3.データ
日本の CO₂排出量を図、一次エネルギー由来消費量及び水力由来消費量を図、化石燃料由来エネルギー
消費量を図、低炭素由来エネルギー消費量を図に示す。

4


---

低炭素

5


---

2.分析手法
先行研究の後には、分析手法（章の名前はふさわしいものに変えてよい）を書く。どんなデータを取
得して、どのような方法で分析したかを分かりやすく述べる。結果についてはまだ述べない。人文社会
系でよくある要因分析のような研究なら、取得データをこの章で示せばいいが、脳波研究のようなもの
は、測定したデータも結果の一部とみなせるので、次の結果の章で示した方がよいことが多い。何を述
べるかをよく考えること。
2.1 研究の流れ
本研究の流れは、以下の通りである。
(1) スマートフォンカメラを使用して画像データを取得する。
(2) 上記で取得した画像のうち、テストデータの画像にペイント加工を加える。具体的には、ランダ
ムな位置・色の正方形を、指定した割合に基づいて配置する。
(3) 学 習 デ ー タ を 利 用 し て 、 公 開 さ れ て い る 学 習 済 み の 畳 み 込 み ニ ュ ー ラ ル ネ ッ ト ワ ー ク
（Convolutional Neural Network：CNN）モデルに対して転移学習を行う。
(4) 加工されたテストデータを用いて評価を行う。加工割合や CNN モデルの条件を変えながら、撮
像カメラの推定精度の変化を確認する。
2.2 使用したデータの概要
本研究では iPhone Xs 2 台、AQUOS sense6 1 台、Galaxy A21 1 台の計 4 台のスマートフォンを使
用し、背面カメラでの撮影によって合計 4400 枚の画像データを取得した。その内訳は、スマートフォ
ン 1 台につき学習データ 1000 枚とテストデータ 100 枚の計 1100 枚である。学習データについては 200
個の被写体から成り、1 つの被写体あたり 5 枚の写真を撮影している。テストデータについては、全て
異なる被写体を撮影している。また、学習済み CNN モデルに対する転移学習を行うために、全ての画
像について、左上からの切り取りにより縦横 250 ピクセルの大きさに統一している。図 1 はテストデー
タの例である。

図 1 テストデータの例
図のタイトルは図の下に書く
このように章の切れ目以外で、下を空けるのはダメ（これは悪い例です）。この場合、2.3 節をこのペ
ージ下部から始めるべきである。
他人の文献の図をそのまま使う場合には必ず「○○より抜粋」と必ずいれること。

6


---

2.3 テストデータに対する加工
※章のタイトルは短くて良いが、各節（セクション）のタイトルは上のようになるべく具体的にした方
がよい（結果的に少し長くなってよい）
テストデータへのペイント加工として、python プログラムによって正方形を配置することで塗りつ
ぶしを行った。具体的には、指定した塗りつぶし割合に基づいて、25×25 サイズの正方形の個数を自動
計算し、画像中のランダムな位置にその個数分の正方形を配置する。さらに、それぞれの正方形の色を
ランダムに変更している。この加工画像の例を図 2 で示す。塗りつぶし割合は、0～10％の 1%刻み、
15%、20％の計 13 段階で指定した。10%以降は 5%刻みになっているのは、これ以降の判別精度の変化
があまり見られなかったためである。

図 2 ペイント加工を施したテストデータの例
2.4 深層学習モデル
本研究では、学習済みの公開されている CNN モデルを使用した転移学習を行う。CNN とは、主に画
像認識やパターン検出に使用される深層学習モデルである。画像内のパターンやエッジを抽出する畳み
込み層と、情報を簡略化するプーリング層から主に構成されており、画像を小さな領域に分けて特徴を
抽出している。
また、転移学習とは深層学習の一手法で、モデルが学習した知識を別のタスクでの学習に適用する方
法である。通常、深層学習モデルはタスクに合わせて大量なデータを必要とするが、転移学習を使用し
て学習済みのモデルや特徴を適用することで、学習データの不足や計算リソースの制約を克服できる。
本研究で使用する画像データは合計で 4400 枚であり、一般的な基準と比較して少ないため、この手法
を採用した。
本研究では転移学習に使用する学習済み公開 CNN モデルとして、VGG16 と ResNet を採用した。
VGG16 は先行研究[4]で使用されており、ResNet は画像認識において高い性能を出すことができる。
また、評価実験での計算リソースが限られることから、この 2 つのモデルを採用した。
VGG16 は 13 個の畳み込み層と 5 個のプーリング層、そして 3 個の全結合層から構成される CNN モ
デルである。畳み込み層では 3×3 の比較的小さなフィルターを使用しており、パラメータ数は増加す
るものの、画像中の局所的な特徴が畳み込み層を通じて階層的に抽出され、豊富な特徴表現を得ること
ができる。畳み込み層とプーリング層、そして全結合層からのシンプルな構造にも関わらず、汎化性能
が高く、小規模のデータセットや計算資源に制約のある状態でも効果的な学習と予測を行うことができ
る。
ResNet は残差ブロックと呼ばれる構造を導入した CNN モデルである。一般的な CNN モデルでは、
層を深くすることで勾配消失と呼ばれる問題が発生する。各パラメータに対する損失関数の勾配が、モ
7


---

デルの出力から入力に逆伝播するが、勾配が小さくなると勾配降下法によるパラメータ更新が難しくな
る。特に最初の層では勾配が非常に小さくなるため、パラメータはほとんど更新されない。これにより
初期の層が適切に学習されず、モデル全体の性能が低下してしまうのが勾配消失である。これに対し
ResNet では残差ブロックを導入することにより、逆伝播の過程で直結した残差が初期の層へ逆伝播さ
れ、その勾配が初期の層のパラメータ更新に寄与する。そして、初期の層でも有益な勾配が残り、勾配
消失の問題が軽減される。これによって ResNet は、特にモデルが非常に深くなる場合でも安定して優
れた学習を行うことができる。
さらに学習アルゴリズムについては、学習率を 0.0001 として最適化アルゴリズム Adam を使用し、
Early Stopping によって、5 エポック連続で検証データに対する的中率が上がらなくなったら重み係数
の学習を停止した。なお、訓練時のパラメータとしてバッチサイズは 64、エポック数は 100、検証デー
タは学習データの 10％を指定した。
本研究での学習環境には、Google Colaboratory を使用した。
2.5 評価方法
学習及びテストデータへの加工をやり直しながら、塗りつぶし割合ごとに 5 回の推定実験を行い、そ
の判別的中率を求める。そうして得られた 5 つの判別的中率の平均値を、その条件における判別精度と
する。この実験を、iPhone Xs と AQUOS sense6 による異なる 2 つのモデル間での推定、2 台の iPhone
Xs による同じ 2 つのモデル間での推定、iPhone Xs と AQUOS sense6 と Galaxy A21 による異なる 3
つのモデル間での推定で行う。

8


---

3.分析結果
手法の後に、得られた結果を述べる（適宜、章タイトルは変えてよい）。研究によっては、結果と考察
を併せて述べた方が書きやすいので、そういう場合は一緒にしてもよい。考察だけ独立させたければ次
の章にする。大概、卒研では何パターンかの分析をするはずなので、パターンごとにセクションを分け
ると書きやすい。
3.1 異なる２つのモデル間での推定結果
※本当は↑の節タイトルの「モデル」の部分は「カメラモデル」とした方がよい（目次だけ見ると、カメ
ラモデルなのか、ニューラルネットワークのモデルなのかが分からないため。節タイトルは目次に並ん
だ時に、書かれている内容をイメージできるものが理想。）
図 3 に、iPhone Xs と AQUOS sense6 の 2 台を使用した実験における推定精度とその変化のグラフ
を示す。塗りつぶし割合が大きくなるにつれて判別的中率が低下している。0～20%の中でも、VGG16
では 3％、ResNet では 4％まで加工割合を増加させると、判別的中率が大きく低下した。一方で、それ
以降の割合においては、精度が低下しにくくなっている。さらに、10%以上の加工画像については、精
度はほとんど 50％になっており、推定能力がほぼ無いことが分かる。
表 1 と表 2 は、塗りつぶし割合が 0%と 10%のときの判別結果に関する混同行列である。0%のときに
はほとんど正しい判別が行われている。一方で 10%のときには、AQUOS の 9 割を iPhone と判別して
しまっており、塗りつぶしが多くなることで、判別が iPhone 寄りになったと考えられる。

図 3 塗りつぶし割合と判別的中率
表 1 塗りつぶし割合 0%のときの混同行列

表のタイトルは表の上に書く

推定

正解

iPhone

AQUOS

iPhone

95%

5%

AQUOS

1%

99%

9


---

表 2 塗りつぶし割合 10%のときの混同行列

推定

正解

iPhone

AQUOS

iPhone

100%

0%

AQUOS

90%

10%

※この例は整数しか現れないため小数点以下を表示していないが一般的には数値は小数点以下 2 桁とか
3 桁くらいで揃えること。
3.2 同じ２つのモデル間での推定結果
図 4 に、iPhone Xs 2 台を使用した実験における推定精度とその変化のグラフを示す。この実験でも、
塗りつぶし割合が大きくなるにつれて判別的中率が低下している。異なる 2 つのモデル間での推定と比
較すると、塗りつぶし割合が低いときの判別的中率は低く、判別的中率は減少しにくくなっている。ま
た、塗りつぶし割合が 10%以降では判別的中率が 50%より大きい点が異なっている。
表 3 と表 4 は、塗りつぶし割合が 0%と 10%のときの判別結果に関する混同行列である。全体的な精
度は低下しているものの、0%のときには大方正しい判別ができている。一方で 10%のときには、片方
の iPhone の 9 割をもう一方の iPhone と判別している。異なる 2 つのモデル間での推定と同様に、塗
りつぶしが大きくなることで、判別が片方寄りになりやすくなっている。

図 4 塗りつぶし割合と判別的中率
表 3 塗りつぶし割合 0%のときの混同行列

推定
iPhone A iPhone B
正解

iPhone A

79%

21%

iPhone B

15%

85%

10


---

表 4 塗りつぶし割合 10%のときの混同行列

推定
iPhone A iPhone B
正解

iPhone A

2%

98%

iPhone B

0%

100%

3.3 異なる３つのモデル間での推定結果
図 5 に、iPhone Xs と AQUOS sense6 と Galaxy A21 の 3 台を使用した実験における推定精度とそ
の変化のグラフを示す。2 台の推定の場合と比較して、低い塗りつぶし割合では比較的高い判別精度で
あったが、割合が高くなると判別精度は低めとなった。
表 5 と表 6 は、塗りつぶし割合が 0%と 10%のときの判別結果に関する混同行列である。推定するモ
デルが 3 つの場合でも、塗りつぶしが大きくなることで、判別が 1 つのモデルに偏るようになってい
る。この推定では Galaxy に偏ったが、AQUOS のほとんどが Galaxy に誤って判別されているのに対
し、iPhone は半分が誤って Galaxy に判別されている。

図 5 塗りつぶし割合と判別的中率
表 5 塗りつぶし割合 0%のときの混同行列

推定

正解

iPhone

AQUOS

Galaxy

iPhone

94%

2%

4%

AQUOS

0%

100%

0%

Galaxy

20%

9%

71%

11


---

表 6 塗りつぶし割合 10%のときの混同行列

推定

正解

iPhone

AQUOS

Galaxy

iPhone

53%

0%

47%

AQUOS

6%

0%

94%

Galaxy

2%

0%

98%

結果を踏まえて、さらなる付加的な実験をした場合には、次に独立した章を作って述べても構わない。
ただし、あまり文量がないならば、「結果」か「考察」の章に組み込んでしまってよい。

12


---

4.考察
本章では、これまでの評価結果を基に考察を述べる。
4-1 評価実験に関する考察
図 3、4、5 から、塗りつぶし割合が増加するに従って判別精度が低下した。PRNU の影響を強く受け
た画素が塗りつぶされることで、判別の手がかりを失ってしまうためである。塗りつぶし割合が大きく
なると、手がかりが少なくなり判別が難しくなってしまう。また表 7 は、異なる 2 つのモデル間での推
定実験において得られた 5 回分の判別的中率とその平均値である。この結果のように、同じ条件下の実
験であっても 10%以上の精度差が生じることもあった。同じ塗りつぶし割合でも、ペイントのランダム
な配置場所によって、精度の差が生じるようであった。
表 7 異なる 2 つのモデル間での 5 回の推定結果と平均値（塗りつぶし割合 4%、ResNet 使用）

１回目

２回目

３回目

４回目

５回目

平均値

60.0

68.0

72.0

60.0

63.5

64.7

また、無加工の場合の推定精度が先行研究と比較して低下しているが、これは画像の性質によるもの
である。本研究ではスマートフォンによる撮影画像をそのまま実験データとして使用しているのに対し、
先行研究では RAW データの公開データセットを用いている。RAW データは、スマートフォンによる
補正を受ける前の画像データであり、PRNU の影響が画素値に表れやすくなっているために、先行研究
の方が高い精度になっていると考えられる。しかし RAW データでなくても、異なる 2 種類のモデルに
おける判別では 94%、異なる 3 種類モデルにおける判別では 90%の精度を得ることができると分かっ
た。
4-2 手法改善に関する評価実験と結果
表 1~6 で示された混同行列から分かるように、塗りつぶし割合が高い場合、推定したクラスが１つに
偏ることが多々あった。この偏りの原因として、単色の正方形を配置する「べた塗り」加工が可能性と
してあると考えた。さらには、この偏りを解消することで、推定精度の向上も期待できると考え、原画
像に近い加工を施して比較することにした。具体的には、ペイント加工部分に、原画像の任意の画素値
を抜き出して貼り付ける加工を行った。この加工画像の例を図 6 に示す。

図 6 元の画像に近いペイント加工をしたテストデータの例

13


---

この方法による加工画像とべた塗りの加工画像をテストデータとする推定結果を比較したものが図 7
である。この実験では、iPhone Xs と AQUOS sense6 の 2 台を使用し、CNN モデルには ResNet を使
用している。べた塗りでない加工にすることで、推定精度が向上した。特に推定の偏りが多かった、塗
りつぶし割合が 10%以降の推定では、15%近くも判別精度が向上している。高い塗りつぶし割合ほど、
偏りが多くなるため、この方法が有効であると分かった。また、塗りつぶし割合の増加に伴う推定精度
の低下も、緩やかなものとなった。
表 7 は、塗りつぶし割合が 10%のときの判別結果に関する混同行列である。依然として判別が iPhone
に偏っているが、表 2 と比較すると 13%のデータについて AQUOS の正しい判別が行われ、偏りが軽
減された。以上のことから、べた塗りでなく原画像由来の塗りつぶしを行うことで、判別の偏りが軽減
され、全体的な判別精度が向上することが分かった。べた塗り加工では画素値の手がかりを失ってしま
うために、モデル側は判別が難しく偏った結果を出しやすくなる。一方でこの加工方法では、手がかり
が別の画素へ移動しただけであり、モデル側は手がかりの場所が異なっても PRNU の影響を受けた画
素値を認識する場合がある。その結果、偏りの改善と判別精度の向上に繋がったのだと考える。

図７

塗りつぶし割合と判別的中率

表 8 塗りつぶし割合 10%のときの混同行列

推定

正解

iPhone

AQUOS

iPhone

100%

0%

AQUOS

77%

23%

14


---

5.結論
「結論」の章は、要は「まとめと今後の課題」と考えてよい。
（研究背景⇒）目的 ⇒ 手法 ⇒ 結果を
改めて書く（結果だけ書くのはダメ；研究背景は書かなくてもよい）、その後に今後の課題を述べる。全
部で 1 ページフル～2 ページくらいは書いて欲しい。
《書き方のポイント》

この章は、総復習＋今後の課題です。
総復習は、これまでのすべての章について、各１段落～２段落くらいでまとめてください。ここま
でに書いてきた章を短くまとめるだけなので簡単なはずです。最後に今後の課題を１段落～２段落
くらいで書いてください。

SNS の普及に伴い、誰もが簡単に画像などのメディアを投稿しやすくなったことで、事件性のある投
稿も増えるようになっている。警察は捜査のために SNS 上の画像や動画の収集を行っており、事件関
係者の特定に利用している。しかし、EXIF 情報などの付加的な情報は改ざんが可能となっているため、
カメラ固有の情報に基づく撮像カメラの特定技術が必要とされている。カメラ固有の情報に基づいた撮
像カメラの推定手法として、半導体素子の性能差を利用する手法がある。半導体素子は光への感度にば
らつきがあり、その影響は画素値に表れる。このばらつきを特徴量とした機械学習によりカメラを推定
する研究が多く行われてきた。しかしこの手法に関する研究において、加工画像に対する推定は扱われ
ていないが、実際には SNS 上で多くの加工画像が投稿されている。また、これらの多くの研究では、
特殊な方法によって得られる RAW データ画像を使用しており、ソフトウェアによる補正を受ける前の、
光への感度のばらつきによる影響が画素値に表れやすくなっている画像を扱っている。そのことから本
研究では、鑑識における実用性の観点から、RAW データでなくスマートフォンによる撮影された画像
データを用いて、畳み込みニューラルネットワークを使用した加工画像に対する撮像カメラの推定に取
り組んだ。
本研究では、スマートフォンカメラによって撮影・ペイント加工を施した画像に対する撮像カメラの
推定を行うことを目的とし、畳み込みニューラルネットワークを用いて判別を行った。実験データには、
2 台の iPhone Xs、1 台の AQUOS sense6、1 台の Galaxy A21 のカメラを使用して撮影した、4000 枚
の学習データと 400 枚のテストデータを使用した。転移学習を行うため、全ての画像を縦横 250 ピクセ
ルに統一している。テストデータについては、python を使用して、任意の場所に 25×25 ピクセルのラ
ンダムな色の正方形を、指定した塗りつぶし割合の個数分配置することでペイント加工を施した。畳み
込みニューラルネットワークには、公開 CNN モデルである VGG16 と ResNet を使用した転移学習を
行った。実験には、iPhone Xs と AQUOS sense6 の異なる 2 つのモデル、iPhone Xs 同士の同じ 2 つ
のモデル、iPhone Xs と AQUOS sense6 と Galaxy A21 の異なる３つのモデル、以上の３通りの推定を
行った。使用する CNN モデルや塗りつぶし割合の条件を変えながら、条件ごとに 5 回ずつ判別的中率
を得て、その平均値を判別精度とした。
評価実験の結果、どの判別においても、塗りつぶし割合が画像全体の 10%までの塗りつぶしであって
も、判別精度は大きく低下した。一方で 10%以降では、判別精度は比較的減少しにくくなった。また、
15


---

特に 10%以上におけるカメラの推定結果は 1 台に偏りが生じやすくなってしまい、この要因が精度の低
下を招いていることが分かった。
そこで本研究では、塗りつぶし方法を単色による「べた塗り」でなく、原画像に由来する画素値を用
いる方法に変えて評価実験を行ったところ、撮像カメラの偏りが軽減され、判別精度も向上した。特に
推定結果の偏りが多かった、塗りつぶし割合 10%以降の画像に対する推定については、判別精度が 15%
近く向上した。
本研究では加工画像としてペイント加工に焦点を当てた。しかし、実際に SNS ではスタンプや落書
きなどによる塗りつぶしだけでなく、拡大・縮小やモザイク加工が施された画像も多く投稿されている。
それらの加工画像に対する撮像カメラの推定精度を調査することで、鑑識における実用性のある結果が
得られると思われる。また、本研究では使用した実験データ数が少ないために転移学習を行い、CNN モ
デルには VGG16 と ResNet の 2 種類を用いた。撮像カメラの推定のための CNN モデルを設計したり、
学習済み公開 CNN モデルに改善を施したりすることで、加工画像にも耐性のある推定モデルが期待で
きると考える。

16


---

謝辞
本研究では、様々なご指導頂きました保坂先生、またアドバイスをくださった研究室の皆に深く感謝し
ております。
謝辞には章番号をつけなくてよい。多くの場合に指導教員に対する謝辞を書くが、書きたくなければ書
かなくてもよい。その他、研究室メンバーの助力が大きかった場合（共同研究の場合など）、外部機関か
ら研究費の援助を受けた場合、家族に対して謝辞を述べたい場合には書くとよい。

17


---

参考文献
[1] 警察庁，「警察におけるサイバー重点施策」，2022 年.
https://www.npa.go.jp/bureau/cyber/what-we-do/about.html
[2] M.Kharrazi, H.T. Sencar, N.Menon, “Blind source camera identification”, IEEE International
Conference on Image Processing ICIP 2004, vol.1, pp.709-712, 2004.
[3] Tiantian Cai, Zhanjian Shao, Yoichi Tomioka, Yuanyuan Liu, Zhu Li, “CNN-based Camera Model
Identification Using Image Noise in Frequency Domain”, 2019 IEEE International Conference on
Systems Man and Cybernetics (SMC), pp.3518-3524, 2019.
[4] Aiswariya Raj, Deepa Sanlar, “Comparison of Deep Learning Networks for Source Camera
Identification”, 2022 4th International Conference on Advances in Computing, Communication
Control and Networking (ICAC3N), pp.1090-1095, 2022.
参考文献にも章番号は不要。各文献につける番号と本文で参照するときの番号は一致させること。また、
ここに挙げるだけで、本文で一度も参照しないのはダメ（必ず本文のどこかで参照すること；参照の際
にはここの番号と合わせること）。
著者の名前，「論文タイトル」，雑誌名，巻番号(vol)，号番号(No や Issue)，ページ(pp)，年．の順で書
くのが基本（英語論文の場合には、タイトルをカギ括弧ではなく、ダブルクォーテーションを使って
‟title” のようにする）。
複数著者がいる場合には、全員の名前を書く。
大学の教科書やプログラミングの参考書のようなものは挙げない。
ネットの記事やブログなども文献としては不適切。
ただし、データを取得したウェブサイトは記載可能。
迷う場合には、事前に相談してください。

18


---

付録 ＊＊＊＊＊のデータ一覧
付録には本文に載せきれない結果やデータなどを載せる。珍しいデバイス（脳波計や kinect など）の使
用方法や授業では教わらないような分析の実装方法は後輩にとって有用となるので基本的に載せてよ
い。一方で、掲載してもまず読まれないような細かい全部の生データなどは載せなくてよい。また、画
像処理やシステム開発のプログラムのソースコードも基本的に不要。付録に載せていいかどうかは事前
に相談すること。本文の対応箇所で必ず「〇〇については付録を参照して頂きたい。」と入れること。
付録が複数ある場合には、付録 1、付録 2、…のようにナンバリングすること。

19


---
